"""
í•œêµ­ ì‹œì¥ ë°ì´í„° íŒŒì´í”„ë¼ì¸ (ë¬´ë£Œ/ê³µì‹ ë°ì´í„° ìš°ì„ )

ë°ì´í„° ì†ŒìŠ¤:
1. KRX íˆ¬ììë³„ ë§¤ë§¤ë™í–¥ (ê¸°ê´€/ì™¸êµ­ì¸/ê°œì¸)
2. OpenDART API (ê³µì‹œ/ì‹¤ì )
3. ë„¤ì´ë²„ ê¸ˆìœµ (ì‹œì„¸/ë‰´ìŠ¤)
4. KIS API (ì‹¤ì‹œê°„ ì‹œì„¸)

ì—…ë°ì´íŠ¸ ì£¼ê¸°:
- ì‹œì„¸: ì‹¤ì‹œê°„ (KIS API)
- ìˆ˜ê¸‰: ì¼ 1íšŒ (KRX, ì¥ ë§ˆê° í›„)
- ê³µì‹œ: ì‹¤ì‹œê°„ (OpenDART)
- ë‰´ìŠ¤: ì‹¤ì‹œê°„ (í¬ë¡¤ë§)
"""

import aiohttp
import asyncio
import os
from typing import Dict, List, Optional
from datetime import datetime, timedelta
import xml.etree.ElementTree as ET
from bs4 import BeautifulSoup


class KoreaDataPipeline:
    """
    í•œêµ­ ì‹œì¥ ë°ì´í„° ìë™ ìˆ˜ì§‘ (ë¬´ë£Œ/ê³µì‹ ìš°ì„ )
    """
    
    def __init__(self):
        self.dart_api_key = os.getenv("OPENDART_API_KEY", "")
        self.naver_headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
    
    # ========== 1) KRX íˆ¬ììë³„ ë§¤ë§¤ë™í–¥ ==========
    
    async def fetch_krx_supply_demand(self, date: Optional[str] = None) -> Dict:
        """
        KRX íˆ¬ììë³„ ë§¤ë§¤ë™í–¥ ìˆ˜ì§‘
        
        Args:
            date: YYYYMMDD (ê¸°ë³¸ê°’: ì–´ì œ)
        
        Returns:
            {
                "stock_code": {
                    "inst_net": ê¸°ê´€ ìˆœë§¤ìˆ˜ (ì›),
                    "foreign_net": ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ (ì›),
                    "retail_net": ê°œì¸ ìˆœë§¤ìˆ˜ (ì›)
                }
            }
        """
        if not date:
            yesterday = datetime.now() - timedelta(days=1)
            date = yesterday.strftime("%Y%m%d")
        
        # KRX ë°ì´í„° í¬í„¸ URL
        url = "http://data.krx.co.kr/comm/bldAttendant/getJsonData.cmd"
        
        payload = {
            "bld": "dbms/MDC/STAT/standard/MDCSTAT02301",
            "trdDd": date,
            "money": "1",  # ê¸ˆì•¡ ê¸°ì¤€
            "csvxls_isNo": "false"
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(url, data=payload, headers=self.naver_headers) as response:
                    if response.status == 200:
                        data = await response.json()
                        return self._parse_krx_data(data)
                    else:
                        print(f"âŒ KRX ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {response.status}")
                        return {}
        except Exception as e:
            print(f"âŒ KRX API ì˜¤ë¥˜: {e}")
            return {}
    
    def _parse_krx_data(self, raw_data: Dict) -> Dict:
        """
        KRX JSON íŒŒì‹±
        """
        result = {}
        
        for item in raw_data.get("OutBlock_1", []):
            stock_code = item.get("ISU_SRT_CD", "")
            
            result[stock_code] = {
                "inst_net": int(item.get("INST_NTBY_QTY", 0)),  # ê¸°ê´€ ìˆœë§¤ìˆ˜
                "foreign_net": int(item.get("FRGN_NTBY_QTY", 0)),  # ì™¸êµ­ì¸
                "retail_net": int(item.get("INDV_NTBY_QTY", 0))  # ê°œì¸
            }
        
        return result
    
    # ========== 2) OpenDART ê³µì‹œ ==========
    
    async def fetch_dart_disclosures(self, date: Optional[str] = None) -> List[Dict]:
        """
        OpenDART ë‹¹ì¼ ê³µì‹œ ì¡°íšŒ
        
        Args:
            date: YYYYMMDD (ê¸°ë³¸ê°’: ì˜¤ëŠ˜)
        
        Returns:
            [
                {
                    "corp_code": ê¸°ì—… ì½”ë“œ,
                    "corp_name": ê¸°ì—…ëª…,
                    "report_nm": ë³´ê³ ì„œëª…,
                    "rcept_dt": ì ‘ìˆ˜ì¼,
                    "flr_nm": ê³µì‹œì
                }
            ]
        """
        if not self.dart_api_key:
            print("âš ï¸ OpenDART API Key ì—†ìŒ. ê³µì‹œ ìˆ˜ì§‘ ë¶ˆê°€.")
            return []
        
        if not date:
            date = datetime.now().strftime("%Y%m%d")
        
        url = "https://opendart.fss.or.kr/api/list.json"
        
        params = {
            "crtfc_key": self.dart_api_key,
            "bgn_de": date,
            "end_de": date,
            "page_count": 100
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        return self._parse_dart_data(data)
                    else:
                        print(f"âŒ OpenDART API ì‹¤íŒ¨: {response.status}")
                        return []
        except Exception as e:
            print(f"âŒ OpenDART API ì˜¤ë¥˜: {e}")
            return []
    
    def _parse_dart_data(self, raw_data: Dict) -> List[Dict]:
        """
        OpenDART JSON íŒŒì‹±
        """
        if raw_data.get("status") != "000":
            return []
        
        disclosures = []
        
        for item in raw_data.get("list", []):
            # ì£¼ìš” ê³µì‹œë§Œ í•„í„°ë§
            important_keywords = [
                "ìˆ˜ì£¼", "ê³„ì•½", "ê²°ì‚°", "ë¶„ê¸°ë³´ê³ ì„œ", "ì‚¬ì—…ë³´ê³ ì„œ", 
                "ì£¼ìš”ì‚¬í•­", "íƒ€ë²•ì¸", "ìœ ìƒì¦ì"
            ]
            
            report_name = item.get("report_nm", "")
            
            if any(kw in report_name for kw in important_keywords):
                disclosures.append({
                    "corp_code": item.get("corp_code", ""),
                    "corp_name": item.get("corp_name", ""),
                    "report_nm": report_name,
                    "rcept_dt": item.get("rcept_dt", ""),
                    "flr_nm": item.get("flr_nm", "")
                })
        
        return disclosures
    
    # ========== 3) ë„¤ì´ë²„ ê¸ˆìœµ ë‰´ìŠ¤ ==========
    
    async def fetch_naver_news(self, stock_code: str, days: int = 7) -> List[Dict]:
        """
        ë„¤ì´ë²„ ê¸ˆìœµ ë‰´ìŠ¤ ìˆ˜ì§‘
        
        Args:
            stock_code: ì¢…ëª© ì½”ë“œ (ì˜ˆ: "005930")
            days: ìµœê·¼ Nì¼
        
        Returns:
            [
                {
                    "title": ì œëª©,
                    "link": ë§í¬,
                    "date": ë‚ ì§œ,
                    "source": ì¶œì²˜
                }
            ]
        """
        url = f"https://finance.naver.com/item/news_news.nhn?code={stock_code}"
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url, headers=self.naver_headers) as response:
                    if response.status == 200:
                        html = await response.text()
                        return self._parse_naver_news(html, days)
                    else:
                        print(f"âŒ ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {response.status}")
                        return []
        except Exception as e:
            print(f"âŒ ë„¤ì´ë²„ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
            return []
    
    def _parse_naver_news(self, html: str, days: int) -> List[Dict]:
        """
        ë„¤ì´ë²„ ë‰´ìŠ¤ HTML íŒŒì‹±
        """
        soup = BeautifulSoup(html, 'html.parser')
        news_items = soup.select('.newsList .articleSubject a')
        
        news_list = []
        cutoff_date = datetime.now() - timedelta(days=days)
        
        for item in news_items[:20]:  # ìµœëŒ€ 20ê°œ
            title = item.get_text().strip()
            link = "https://finance.naver.com" + item.get('href', '')
            
            news_list.append({
                "title": title,
                "link": link,
                "date": datetime.now().strftime("%Y-%m-%d"),
                "source": "ë„¤ì´ë²„ ê¸ˆìœµ"
            })
        
        return news_list
    
    # ========== 4) ì¢…í•© ë°ì´í„° ìˆ˜ì§‘ ==========
    
    async def collect_daily_data(self, stock_codes: List[str]) -> Dict:
        """
        ë§¤ì¼ ì¥ ë§ˆê° í›„ ìë™ ìˆ˜ì§‘
        
        Args:
            stock_codes: ["005930", "000660", ...]
        
        Returns:
            {
                "supply_demand": {...},
                "disclosures": [...],
                "news": {...},
                "timestamp": "2026-01-27 16:00:00"
            }
        """
        print(f"ğŸ“Š í•œêµ­ ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ({len(stock_codes)}ê°œ ì¢…ëª©)")
        
        # ë³‘ë ¬ ìˆ˜ì§‘
        tasks = [
            self.fetch_krx_supply_demand(),
            self.fetch_dart_disclosures()
        ]
        
        results = await asyncio.gather(*tasks)
        
        supply_demand = results[0]
        disclosures = results[1]
        
        # ë‰´ìŠ¤ëŠ” ì¢…ëª©ë³„ë¡œ ìˆ˜ì§‘ (ì‹œê°„ ì œì•½ ê³ ë ¤)
        news = {}
        for code in stock_codes[:10]:  # ìµœëŒ€ 10ê°œ ì¢…ëª©ë§Œ
            news[code] = await self.fetch_naver_news(code)
        
        return {
            "supply_demand": supply_demand,
            "disclosures": disclosures,
            "news": news,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
    
    # ========== 5) ì„¹í„° ë¶„ë¥˜ (GICS) ==========
    
    def classify_sector(self, stock_code: str) -> str:
        """
        ì¢…ëª©ì„ ì„¹í„°ë¡œ ë¶„ë¥˜
        
        âš ï¸ ê°„ë‹¨í•œ ë§¤í•‘. ì‹¤ì „ì—ì„œëŠ” KRX ì—…ì¢… ë°ì´í„° ì‚¬ìš©.
        """
        sector_map = {
            # ë°©ì‚°
            "012450": "ë°©ì‚°",  # í•œí™”ì—ì–´ë¡œìŠ¤í˜ì´ìŠ¤
            "047810": "ë°©ì‚°",  # í•œêµ­í•­ê³µìš°ì£¼
            
            # í—¬ìŠ¤ì¼€ì–´
            "207940": "í—¬ìŠ¤ì¼€ì–´",  # ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤
            "068270": "í—¬ìŠ¤ì¼€ì–´",  # ì…€íŠ¸ë¦¬ì˜¨
            "326030": "í—¬ìŠ¤ì¼€ì–´",  # SKë°”ì´ì˜¤íŒœ
            
            # AI ë°˜ë„ì²´
            "005930": "AI ë°˜ë„ì²´",  # ì‚¼ì„±ì „ì
            "000660": "AI ë°˜ë„ì²´",  # SKí•˜ì´ë‹‰ìŠ¤
            
            # ì „ë ¥
            "015760": "ì „ë ¥",  # í•œêµ­ì „ë ¥
            
            # ì—ë„ˆì§€
            "010950": "ì—ë„ˆì§€",  # S-Oil
        }
        
        return sector_map.get(stock_code, "ê¸°íƒ€")
    
    # ========== 6) ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ==========
    
    def validate_data(self, data: Dict) -> bool:
        """
        ìˆ˜ì§‘ëœ ë°ì´í„° í’ˆì§ˆ ê²€ì¦
        """
        checks = {
            "supply_demand": len(data.get("supply_demand", {})) > 0,
            "disclosures": isinstance(data.get("disclosures", []), list),
            "news": len(data.get("news", {})) > 0
        }
        
        passed = sum(checks.values())
        total = len(checks)
        
        print(f"âœ… ë°ì´í„° í’ˆì§ˆ ê²€ì¦: {passed}/{total} í†µê³¼")
        
        for name, result in checks.items():
            status = "âœ…" if result else "âŒ"
            print(f"  {status} {name}")
        
        return passed >= 2  # ìµœì†Œ 2ê°œ ì´ìƒ í†µê³¼


# ========== í…ŒìŠ¤íŠ¸ ==========

async def test_pipeline():
    """
    íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
    """
    pipeline = KoreaDataPipeline()
    
    # í…ŒìŠ¤íŠ¸ ì¢…ëª©
    test_stocks = ["005930", "012450", "207940"]
    
    print("=" * 60)
    print("í•œêµ­ ë°ì´í„° íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # 1) KRX ìˆ˜ê¸‰
    print("\n1ï¸âƒ£ KRX íˆ¬ììë³„ ë§¤ë§¤ë™í–¥")
    supply_demand = await pipeline.fetch_krx_supply_demand()
    print(f"  ìˆ˜ì§‘ ì¢…ëª© ìˆ˜: {len(supply_demand)}")
    
    # 2) OpenDART ê³µì‹œ
    print("\n2ï¸âƒ£ OpenDART ê³µì‹œ")
    disclosures = await pipeline.fetch_dart_disclosures()
    print(f"  ì£¼ìš” ê³µì‹œ ìˆ˜: {len(disclosures)}")
    if disclosures:
        print(f"  ì˜ˆì‹œ: {disclosures[0]['corp_name']} - {disclosures[0]['report_nm']}")
    
    # 3) ë„¤ì´ë²„ ë‰´ìŠ¤
    print("\n3ï¸âƒ£ ë„¤ì´ë²„ ê¸ˆìœµ ë‰´ìŠ¤")
    news = await pipeline.fetch_naver_news("005930")
    print(f"  ì‚¼ì„±ì „ì ë‰´ìŠ¤ ìˆ˜: {len(news)}")
    if news:
        print(f"  ì˜ˆì‹œ: {news[0]['title']}")
    
    # 4) ì¢…í•© ìˆ˜ì§‘
    print("\n4ï¸âƒ£ ì¢…í•© ë°ì´í„° ìˆ˜ì§‘")
    all_data = await pipeline.collect_daily_data(test_stocks)
    
    # 5) í’ˆì§ˆ ê²€ì¦
    print("\n5ï¸âƒ£ ë°ì´í„° í’ˆì§ˆ ê²€ì¦")
    is_valid = pipeline.validate_data(all_data)
    
    if is_valid:
        print("\nâœ… íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
    else:
        print("\nâš ï¸ ì¼ë¶€ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")


if __name__ == "__main__":
    # ë¹„ë™ê¸° ì‹¤í–‰
    asyncio.run(test_pipeline())
